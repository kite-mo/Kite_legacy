{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import dataset_, model_, train_, inference_\n",
    "from src.utils import *\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device('cuda:{}'.format(0) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oes_sensor_numbers = 30\n",
    "sensor_list = [f'OES_{num}' for num in range(1, oes_sensor_numbers + 1)]\n",
    "pretrain_data_num, train_data_num, test_data_num = 100, 400, 200\n",
    "\n",
    "data_num_dict = {\n",
    "    'pre_train' : pretrain_data_num,\n",
    "    'train' : train_data_num,\n",
    "    'test' : test_data_num\n",
    "}\n",
    "\n",
    "min_data_length, max_data_length = 103, 109\n",
    "data_key_list = ['key']\n",
    "\n",
    "dataset_df_dict = {}\n",
    "for idx, (dataset_name, data_num_range) in enumerate(data_num_dict.items()):\n",
    "    dataset_df_list = []\n",
    "    for data_index in range(data_num_range):\n",
    "        if idx == 1:\n",
    "            classes = [0, 1, -1]\n",
    "            class_probabilities = [0.7, 0.2, 0.1]\n",
    "        elif idx == 2:\n",
    "            classes = [0, 1]\n",
    "            class_probabilities = [0.8, 0.2]\n",
    "        else:\n",
    "            classes = [0]\n",
    "            class_probabilities = [1.0]\n",
    "        \n",
    "        sampling_size = random.sample(range(min_data_length, max_data_length), 1)[0]\n",
    "        class_label = random.choices(classes, class_probabilities, k=1)[0]    \n",
    "\n",
    "        generation_array = np.random.rand(sampling_size, oes_sensor_numbers)\n",
    "        generation_df = pd.DataFrame(generation_array, columns=sensor_list)\n",
    "        generation_df['key'] = data_index\n",
    "        generation_df['label'] = class_label\n",
    "        dataset_df_list.append(generation_df.reset_index(drop=True))\n",
    "\n",
    "    dataset_df_dict[dataset_name] = dataset_df_list\n",
    "\n",
    "pre_train_set, train_set, test_set = dataset_df_dict['pre_train'], dataset_df_dict['train'], dataset_df_dict['test']\n",
    "\n",
    "fin_dataset_list = [pre_train_set, train_set, test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Datalaoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max_data_length\n",
    "\n",
    "pre_train_dataset = dataset_.dataset_ae(fin_dataset_list[0], max_len, sensor_list)\n",
    "train_dataset = dataset_.dataset_ae(fin_dataset_list[1], max_len, sensor_list)\n",
    "test_dataset = dataset_.dataset_ae(fin_dataset_list[2], max_len, sensor_list)\n",
    "\n",
    "pre_train_loader = DataLoader(pre_train_dataset, batch_size=20, drop_last=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, drop_last=True, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=12, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_num = pre_train_dataset[0][0].shape[0]\n",
    "latent_dim = 100\n",
    "pre_model = model_.base_AE(sensor_num, latent_dim).to(device)\n",
    "\n",
    "test_tensor = torch.rand(15, sensor_num, pre_train_dataset[0][0].shape[1]).to(device)\n",
    "squeezed_x, squeezed_x_hat, latent_x, layer_output = pre_model(test_tensor)\n",
    "\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "\n",
    "loss = train_.loss_base_ae(pre_model, test_tensor, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Hypersphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 26.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# hyper parameters\n",
    "final_center = inference_.get_hypersphere_center(pre_model, pre_train_loader, \n",
    "                                                 device, type = 'ae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SS-LAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach pre train Encoder parameter to Deep_SAD\n",
    "AE = model_.base_AE(sensor_num, latent_dim).to(device)\n",
    "deep_sad_model = AE.encoder\n",
    "\n",
    "# hyper parameters\n",
    "n_epochs = 500\n",
    "lr = 0.001\n",
    "eta = 10 # 레이블 데이터에 대한 가중치 정도\n",
    "eps = 1e-6 # dist 를 최소 0 초과로 만들기 위함\n",
    "type_ = 'ae'\n",
    "\n",
    "deep_sad_model.train()\n",
    "for batch, (data, label) in enumerate(train_loader, 1):\n",
    "    data = data.float().to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    # calculate the loss\n",
    "    dist, loss = train_.deep_sad_loss(data, label, deep_sad_model, \n",
    "                                      final_center, eta, eps, type_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kitemo_env_240708",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
